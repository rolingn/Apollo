{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset to HuggingFace Hub for InsectSAM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca019b3a041f43c8b2e81b97b9b21252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d46898fb4b949d19905593010656604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e04b0f4e49f430bb590bb4e26922737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44185585c88d43f7afc399a64d865ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/martintmv/rb-ibdm/commit/63c596331d34f96707ff34d347ff8c237b210e1e', commit_message='Upload dataset', commit_description='', oid='63c596331d34f96707ff34d347ff8c237b210e1e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Image, load_dataset\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "data_dir = \"/Users/martintomov/Desktop/dataset\"\n",
    "\n",
    "# Helper function to encode image files as RGB\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        image = PILImage.open(image_file)\n",
    "        image = image.convert(\"RGB\") \n",
    "        byte_io = io.BytesIO()\n",
    "        image.save(byte_io, 'PNG')\n",
    "        return byte_io.getvalue()\n",
    "\n",
    "# Helper function to encode label files without changing their color mode\n",
    "def encode_label(label_path):\n",
    "    with open(label_path, 'rb') as label_file:\n",
    "        label = PILImage.open(label_file)\n",
    "        byte_io = io.BytesIO()\n",
    "        label.save(byte_io, 'PNG')\n",
    "        return byte_io.getvalue()\n",
    "\n",
    "image_files = sorted([os.path.join(data_dir, 'image', file) for file in os.listdir(os.path.join(data_dir, 'image')) if file.endswith('.png')])\n",
    "label_files = sorted([os.path.join(data_dir, 'label', file) for file in os.listdir(os.path.join(data_dir, 'label')) if file.endswith('.png')])\n",
    "\n",
    "assert len(image_files) == len(label_files), \"The number of images and labels should be the same\"\n",
    "\n",
    "data = []\n",
    "for image_path, label_path in zip(image_files, label_files):\n",
    "    data.append({\n",
    "        'image': encode_image(image_path),\n",
    "        'label': encode_label(label_path)\n",
    "    })\n",
    "\n",
    "features = Features({'image': Image(), 'label': Image()})\n",
    "\n",
    "# Create a Dataset object\n",
    "dataset = Dataset.from_dict({'image': [item['image'] for item in data], 'label': [item['label'] for item in data]}, features=features)\n",
    "\n",
    "# Convert to a DatasetDict\n",
    "dataset = DatasetDict({'train': dataset})\n",
    "\n",
    "# Authenticate with Hugging Face and push the dataset\n",
    "dataset.push_to_hub(\"martintmv/rb-ibdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
